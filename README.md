# ğŸŒ¦ Weather Data Pipeline - SÃ£o Paulo

End-to-end ETL pipeline that extracts real-time weather data for SÃ£o
Paulo using the OpenWeather API, transforms it using Pandas, and loads
it into PostgreSQL. The pipeline is orchestrated using Apache Airflow
and fully containerized with Docker.

------------------------------------------------------------------------

## ğŸ“Œ Project Overview

This project simulates a production-ready data engineering workflow:

-   Extract weather data from external API
-   Transform nested JSON into structured tabular format
-   Load processed data into PostgreSQL
-   Orchestrate tasks using Airflow DAG
-   Containerized environment with Docker

## ğŸ— Architecture

<p align="center">
  <img src="docs/architecture.png" width="800"/>
</p>

------------------------------------------------------------------------

## ğŸ›  Tech Stack

-   Python 3.12
-   Pandas
-   Apache Airflow
-   Docker & Docker Compose
-   PostgreSQL
-   python-dotenv
-   uv (Python package manager)

## ğŸ”— Data Source

This project consumes real-time weather data from the OpenWeather API:

- API Documentation: https://openweathermap.org/current
- Endpoint used: https://api.openweathermap.org/data/2.5/weather

## ğŸ“‚ Project Structure

    weather_data_pipeline/
    â”‚
    â”œâ”€â”€ dags/
    â”œâ”€â”€ src/
    â”œâ”€â”€ data/
    â”œâ”€â”€ config/
    â”œâ”€â”€ docs/
    â”‚   â””â”€â”€ architecture.png
    â”œâ”€â”€ docker-compose.yaml
    â””â”€â”€ README.md

------------------------------------------------------------------------

## âš™ï¸ How It Works

### 1ï¸âƒ£ Extract

Fetches weather data from OpenWeather API.

### 2ï¸âƒ£ Transform

-   Flattens nested JSON
-   Normalizes weather fields
-   Cleans column names
-   Stores intermediate result as Parquet

### 3ï¸âƒ£ Load

-   Reads processed data
-   Inserts into PostgreSQL table `sp_weather`

------------------------------------------------------------------------

## ğŸš€ Running the Project

### 1. Set environment variable

Create a `.env` file inside `config/`:

    api_key=YOUR_OPENWEATHER_API_KEY

### 2. Start containers

    docker compose up -d

### 3. Access Airflow UI

    http://localhost:8080

Enable DAG:

    weather_pipeline

## ğŸ“Š Example Output Columns

| Column              | Description                 |
|---------------------|-----------------------------|
| temp                | Current temperature         |
| humidity            | Air humidity                |
| wind_speed          | Wind speed                  |
| weather_main        | Weather category            |
| weather_description | Detailed condition          |
| datetime            | Data extraction timestamp   |


## ğŸ¯ Learning Goals

This project demonstrates:

-   API integration
-   JSON normalization
-   Data transformation with Pandas
-   Airflow DAG development
-   Docker containerization
-   ETL best practices

------------------------------------------------------------------------

## ğŸ”® Future Improvements

-   Store historical weather data
-   Deploy to cloud environment (GCP)
-   Add monitoring and alerts

------------------------------------------------------------------------

## ğŸ‘©â€ğŸ’» Author

Adria Freitas
